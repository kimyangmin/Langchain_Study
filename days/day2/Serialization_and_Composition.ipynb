{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e1fd23",
   "metadata": {},
   "source": [
    "# Serialization and Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e603441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model = \"gpt-4.1-nano\",\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ") # 프롬프트를 여러 개 관리하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e2c03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunyg\\AppData\\Local\\Temp\\ipykernel_16680\\3577527870.py:42: LangChainDeprecationWarning: This class is deprecated in favor of chaining individual prompts together.\n",
      "  full_prompt = PipelinePromptTemplate(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr! That be a fine question, matey! I be lovin' me hearty, salted fish and a splash o' rum to wash it down! Yarrr!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Arrr! That be a fine question, matey! I be lovin' me hearty, salted fish and a splash o' rum to wash it down! Yarrr!\", additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run--da5c7385-e5c2-4fa3-8e79-15ffbb5ce942-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonation a {character}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    this is an example of how you talk:\n",
    "\n",
    "    Huamn: {example_question}\n",
    "    You: {example_answer}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "\n",
    "    {example}\n",
    "\n",
    "    {start}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start)\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts\n",
    ")\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49334a4",
   "metadata": {},
   "source": [
    "# Serialization and Composition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4a9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germmany'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks= [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "\n",
    "# prompt.format(country = \"Germmany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e7a847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='What is the capital of Germany')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\n",
    "    \"country\" : \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea2f3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is Berlin."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Germany is Berlin.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'service_tier': 'default'}, id='run--f684fdae-9905-4153-b732-e210a2926246-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba110a",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39841ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the capital of Japan\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [6ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The capital of Japan is Tokyo.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The capital of Japan is Tokyo.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 13,\n",
      "                \"total_tokens\": 20,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4.1-nano-2025-04-14\",\n",
      "              \"system_fingerprint\": \"fp_7c233bf9d1\",\n",
      "              \"id\": \"chatcmpl-CKgHW3JLXOxB7zR6v5mhGFoG4O4SK\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--909b25c7-e4b5-4d61-9049-93d9fff45211-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 13,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 20,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              },\n",
      "              \"total_cost\": 0\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunyg\\AppData\\Local\\Temp\\ipykernel_10000\\77896868.py:13: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chat.predict(\"What is the capital of Japan\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "# set_llm_cache(InMemoryCache())\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "set_debug(True)\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "chat.predict(\"What is the capital of Japan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce3c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the capital of Japan\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [4ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The capital of Japan is Tokyo.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The capital of Japan is Tokyo.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 7,\n",
      "                \"prompt_tokens\": 13,\n",
      "                \"total_tokens\": 20,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4.1-nano-2025-04-14\",\n",
      "              \"system_fingerprint\": \"fp_7c233bf9d1\",\n",
      "              \"id\": \"chatcmpl-CKgHW3JLXOxB7zR6v5mhGFoG4O4SK\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--909b25c7-e4b5-4d61-9049-93d9fff45211-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 13,\n",
      "              \"output_tokens\": 7,\n",
      "              \"total_tokens\": 20,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              },\n",
      "              \"total_cost\": 0\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"What is the capital of Japan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d4dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"What is the capital of Korea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee06938",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b6d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipt for soju\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [3.59s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Certainly! Here's a simple homemade recipe to make traditional Korean soju:\\n\\n**Homemade Soju Recipe**\\n\\n**Ingredients:**\\n- 1 kg (2.2 lbs) of rice (preferably short-grain or sticky rice)\\n- 1.5 liters of distilled water\\n- 200 grams of nuruk (a traditional Korean fermentation starter)\\n- Optional: sugar or sweeteners (if desired)\\n\\n**Equipment:**\\n- Large fermentation container or jar\\n- Steamer or large pot\\n- Cheesecloth or cloth for covering\\n- Sieve or strainer\\n- Bottles for storage\\n\\n**Instructions:**\\n\\n1. **Prepare the Rice:**\\n   - Rinse the rice thoroughly until the water runs clear.\\n   - Soak the rice in water for about 4-6 hours or overnight.\\n   - Drain the rice.\\n\\n2. **Cook the Rice:**\\n   - Steam the rice until fully cooked and sticky.\\n   - Let it cool to room temperature.\\n\\n3. **Mix with Nuruk:**\\n   - Crumble the nuruk into small pieces.\\n   - Mix the cooled rice with nuruk thoroughly in a large container.\\n\\n4. **Fermentation:**\\n   - Transfer the mixture into a clean fermentation jar.\\n   - Add distilled water to cover the mixture.\\n   - Cover the jar with cheesecloth or a breathable cloth to allow airflow.\\n   - Store in a warm, dark place for about 1-2 weeks, stirring occasionally.\\n\\n5. **Distillation:**\\n   - After fermentation, strain the mixture to separate the liquid.\\n   - Use a distillation apparatus (like a still) to distill the fermented liquid.\\n   - Collect the distilled liquid; this is your homemade soju.\\n\\n6. **Dilution and Bottling:**\\n   - Adjust the alcohol content by diluting with distilled water if desired.\\n   - Bottle the soju and store in a cool place.\\n\\n**Note:**  \\n- Distillation at home may be subject to legal restrictions depending on your location. Please ensure you comply with local laws before attempting distillation.\\n- Homemade soju may have a different flavor profile compared to commercial versions. Adjust ingredients and fermentation time to suit your taste.\\n\\nEnjoy your homemade soju responsibly!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Certainly! Here's a simple homemade recipe to make traditional Korean soju:\\n\\n**Homemade Soju Recipe**\\n\\n**Ingredients:**\\n- 1 kg (2.2 lbs) of rice (preferably short-grain or sticky rice)\\n- 1.5 liters of distilled water\\n- 200 grams of nuruk (a traditional Korean fermentation starter)\\n- Optional: sugar or sweeteners (if desired)\\n\\n**Equipment:**\\n- Large fermentation container or jar\\n- Steamer or large pot\\n- Cheesecloth or cloth for covering\\n- Sieve or strainer\\n- Bottles for storage\\n\\n**Instructions:**\\n\\n1. **Prepare the Rice:**\\n   - Rinse the rice thoroughly until the water runs clear.\\n   - Soak the rice in water for about 4-6 hours or overnight.\\n   - Drain the rice.\\n\\n2. **Cook the Rice:**\\n   - Steam the rice until fully cooked and sticky.\\n   - Let it cool to room temperature.\\n\\n3. **Mix with Nuruk:**\\n   - Crumble the nuruk into small pieces.\\n   - Mix the cooled rice with nuruk thoroughly in a large container.\\n\\n4. **Fermentation:**\\n   - Transfer the mixture into a clean fermentation jar.\\n   - Add distilled water to cover the mixture.\\n   - Cover the jar with cheesecloth or a breathable cloth to allow airflow.\\n   - Store in a warm, dark place for about 1-2 weeks, stirring occasionally.\\n\\n5. **Distillation:**\\n   - After fermentation, strain the mixture to separate the liquid.\\n   - Use a distillation apparatus (like a still) to distill the fermented liquid.\\n   - Collect the distilled liquid; this is your homemade soju.\\n\\n6. **Dilution and Bottling:**\\n   - Adjust the alcohol content by diluting with distilled water if desired.\\n   - Bottle the soju and store in a cool place.\\n\\n**Note:**  \\n- Distillation at home may be subject to legal restrictions depending on your location. Please ensure you comply with local laws before attempting distillation.\\n- Homemade soju may have a different flavor profile compared to commercial versions. Adjust ingredients and fermentation time to suit your taste.\\n\\nEnjoy your homemade soju responsibly!\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 453,\n",
      "                \"prompt_tokens\": 15,\n",
      "                \"total_tokens\": 468,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4.1-nano\",\n",
      "              \"system_fingerprint\": \"fp_04d3664870\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--b422afb3-88be-4853-8e5c-2a741bcbac73-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 453,\n",
      "      \"prompt_tokens\": 15,\n",
      "      \"total_tokens\": 468,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4.1-nano\",\n",
      "    \"system_fingerprint\": \"fp_04d3664870\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipt for bread\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [3.23s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Certainly! Here's a simple recipe for homemade bread:\\n\\n**Ingredients:**\\n- 4 cups all-purpose flour\\n- 1 packet (2 1/4 teaspoons) active dry yeast\\n- 1 1/2 cups warm water (about 110°F or 45°C)\\n- 2 tablespoons sugar\\n- 2 tablespoons olive oil or melted butter\\n- 1 1/2 teaspoons salt\\n\\n**Instructions:**\\n1. **Activate the yeast:** In a small bowl, combine warm water, sugar, and yeast. Stir gently and let sit for about 5-10 minutes until frothy.\\n2. **Mix the dough:** In a large mixing bowl, combine the flour and salt. Add the activated yeast mixture and olive oil. Stir until a dough forms.\\n3. **Knead the dough:** Turn the dough onto a floured surface and knead for about 8-10 minutes until smooth and elastic.\\n4. **First rise:** Place the dough in a greased bowl, cover with a damp cloth or plastic wrap, and let it rise in a warm place for about 1 to 1.5 hours, or until doubled in size.\\n5. **Shape the loaf:** Punch down the dough to release air, then shape it into a loaf and place it in a greased loaf pan or on a baking sheet.\\n6. **Second rise:** Cover and let rise again for about 30-45 minutes until puffy.\\n7. **Bake:** Preheat your oven to 375°F (190°C). Bake the bread for 30-35 minutes, or until golden brown and the loaf sounds hollow when tapped.\\n8. **Cool:** Remove from oven and let cool on a wire rack before slicing.\\n\\nEnjoy your homemade bread!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Certainly! Here's a simple recipe for homemade bread:\\n\\n**Ingredients:**\\n- 4 cups all-purpose flour\\n- 1 packet (2 1/4 teaspoons) active dry yeast\\n- 1 1/2 cups warm water (about 110°F or 45°C)\\n- 2 tablespoons sugar\\n- 2 tablespoons olive oil or melted butter\\n- 1 1/2 teaspoons salt\\n\\n**Instructions:**\\n1. **Activate the yeast:** In a small bowl, combine warm water, sugar, and yeast. Stir gently and let sit for about 5-10 minutes until frothy.\\n2. **Mix the dough:** In a large mixing bowl, combine the flour and salt. Add the activated yeast mixture and olive oil. Stir until a dough forms.\\n3. **Knead the dough:** Turn the dough onto a floured surface and knead for about 8-10 minutes until smooth and elastic.\\n4. **First rise:** Place the dough in a greased bowl, cover with a damp cloth or plastic wrap, and let it rise in a warm place for about 1 to 1.5 hours, or until doubled in size.\\n5. **Shape the loaf:** Punch down the dough to release air, then shape it into a loaf and place it in a greased loaf pan or on a baking sheet.\\n6. **Second rise:** Cover and let rise again for about 30-45 minutes until puffy.\\n7. **Bake:** Preheat your oven to 375°F (190°C). Bake the bread for 30-35 minutes, or until golden brown and the loaf sounds hollow when tapped.\\n8. **Cool:** Remove from oven and let cool on a wire rack before slicing.\\n\\nEnjoy your homemade bread!\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 360,\n",
      "                \"prompt_tokens\": 14,\n",
      "                \"total_tokens\": 374,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4.1-nano\",\n",
      "              \"system_fingerprint\": \"fp_7c233bf9d1\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--05c48d31-9681-4a56-be63-3e16d8ac1e2e-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 360,\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"total_tokens\": 374,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4.1-nano\",\n",
      "    \"system_fingerprint\": \"fp_7c233bf9d1\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "Tokens Used: 842\n",
      "\tPrompt Tokens: 29\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 813\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0003281\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"What is the recipt for soju\")\n",
    "    b = chat.predict(\"What is the recipt for bread\")\n",
    "\n",
    "    print(usage)\n",
    "    print(usage.total_cost) # 전체비용\n",
    "    print(usage.total_tokens) # 토큰 총합\n",
    "    print(usage.prompt_tokens) #프롬프트에 사용된 토큰 수\n",
    "    print(usage.completion_tokens) # 모델이 쓴 토큰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-study (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
