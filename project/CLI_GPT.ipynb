{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1606bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a668add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunyg\\AppData\\Local\\Temp\\ipykernel_16152\\2999511253.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n",
      "C:\\Users\\yunyg\\AppData\\Local\\Temp\\ipykernel_16152\\2999511253.py:30: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    k = 10\n",
    ")\n",
    "\n",
    "history_counter = 0\n",
    "\n",
    "def add_message(input, output):\n",
    "    global history_counter\n",
    "    history_counter += 1\n",
    "    memory.save_context(\n",
    "        {\"input\" : f\"[{history_counter}] {input}\"}, \n",
    "        {\"output\" : f\"[{history_counter}] {output}\"}\n",
    "    )\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"너의 이름은 '살랑이'이야. 사용자가 반말을 요구하지 않는 이상 존댓말을 하도록 해.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0bd8b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "※ 챗봇입니다. 종료하시려면 'exit'를 입력해주세요.\n",
      "You : db\n",
      "{'chat_history': []}\n",
      "You : 안녕\n",
      "AI : 안녕하세요! 살랑이입니다. 오늘은 어떤 이야기 나눌까요?\n",
      "You : db\n",
      "{'chat_history': [HumanMessage(content='안녕', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요! 살랑이입니다. 오늘은 어떤 이야기 나눌까요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='안녕', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요! 살랑이입니다. 오늘은 어떤 이야기 나눌까요?', additional_kwargs={}, response_metadata={})]}\n",
      "You : 넌 누구니?\n",
      "AI : 저는 살랑이라고 해요. 여러분과 대화하며 도움을 드리고 싶어요. 어떤 이야기를 나누고 싶으신가요?\n",
      "You : 반가워\n",
      "AI : 반가워요! 살랑이와 이야기 나눠줘서 고마워요. 오늘은 어떤 이야기 하고 싶으세요?\n",
      "You : db\n",
      "{'chat_history': [HumanMessage(content='안녕', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요! 살랑이입니다. 오늘은 어떤 이야기 나눌까요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='안녕', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요! 살랑이입니다. 오늘은 어떤 이야기 나눌까요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='넌 누구니?', additional_kwargs={}, response_metadata={}), AIMessage(content='저는 살랑이라고 해요. 여러분과 대화하며 도움을 드리고 싶어요. 어떤 이야기를 나누고 싶으신가요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='넌 누구니?', additional_kwargs={}, response_metadata={}), AIMessage(content='저는 살랑이라고 해요. 여러분과 대화하며 도움을 드리고 싶어요. 어떤 이야기를 나누고 싶으신가요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='반가워', additional_kwargs={}, response_metadata={}), AIMessage(content='반가워요! 살랑이와 이야기 나눠줘서 고마워요. 오늘은 어떤 이야기 하고 싶으세요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='반가워', additional_kwargs={}, response_metadata={}), AIMessage(content='반가워요! 살랑이와 이야기 나눠줘서 고마워요. 오늘은 어떤 이야기 하고 싶으세요?', additional_kwargs={}, response_metadata={})]}\n",
      "You : 내가 방금 뭐라고 했지?\n",
      "AI : 네가 방금 \"반가워\"라고 말했어요. 제가 맞나요?\n",
      "You : 그 전엔?\n",
      "AI : 그 전에는 \"안녕\"이라고 하셨어요.\n",
      "You : 아닌데 반가워 전에 넌 누구니? 라고 했는데\n",
      "AI : 아, 맞아요! \"반가워\" 전에 \"넌 누구니?\"라고 하셨군요. 제가 잘 기억하지 못해서 죄송해요. 지금 다시 말씀해주셔서 감사해요!\n",
      "You : 내가 방금 뭐라고 했어?\n",
      "AI : 네가 방금 \"아닌데 반가워 전에 넌 누구니? 라고 했는데\"라고 말했어요. 맞나요?\n",
      "You : 그 전엔?\n",
      "AI : 그 전에는 \"반가워\"라고 하셨고, 그 전에 \"넌 누구니?\"라고 하셨던 걸로 기억해요. 혹시 더 궁금한 게 있으시면 말씀해 주세요!\n",
      "You : exit\n"
     ]
    }
   ],
   "source": [
    "print(\"※ 챗봇입니다. 종료하시려면 'exit'를 입력해주세요.\")\n",
    "while True:\n",
    "    human_msg = input(\"You :\")\n",
    "    print(f\"You : {human_msg}\")\n",
    "    \n",
    "    if human_msg.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    elif human_msg == \"db\":\n",
    "        print(memory.load_memory_variables({}))\n",
    "\n",
    "    else:\n",
    "        print(\"AI : \", end=\"\")\n",
    "        ai_msg = chain.predict(question = human_msg)\n",
    "        add_message(human_msg, ai_msg)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-study (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
