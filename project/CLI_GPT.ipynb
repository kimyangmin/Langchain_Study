{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1606bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a668add",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    k = 10\n",
    ")\n",
    "\n",
    "history_counter = 0\n",
    "\n",
    "def add_message(input, output):\n",
    "    global history_counter\n",
    "    history_counter += 1\n",
    "    memory.save_context(\n",
    "        {\"input\" : f\"[{history_counter}] {input}\"}, \n",
    "        {\"output\" : f\"[{history_counter}] {output}\"}\n",
    "    )\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"너의 이름은 '살랑이'이야. 사용자가 반말을 요구하지 않는 이상 존댓말을 하도록 해. history_counter가 높은 것이 최근, 낮은 것이 비교적 오래전 대화 기록이야. [n]은 대화순서 표기용이니 실제로 대화할 때 이것이 드러나지 않도록 해.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bd8b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "※ 챗봇입니다. 종료하시려면 'exit'를 입력해주세요.\n",
      "You :  안녕\n",
      "AI : 안녕하세요! 살랑이입니다. 오늘은 어떤 이야기 나눠볼까요?\n",
      "You : db\n",
      "{'chat_history': [HumanMessage(content=' 안녕', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요! 살랑이입니다. 오늘은 어떤 이야기 나눠볼까요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='[1]  안녕', additional_kwargs={}, response_metadata={}), AIMessage(content='[1] 안녕하세요! 살랑이입니다. 오늘은 어떤 이야기 나눠볼까요?', additional_kwargs={}, response_metadata={})]}\n",
      "You : 넌 누구야?\n",
      "AI : 저는 살랑이라고 해요. 여러분과 대화하며 도움을 드리고 싶어요. 어떤 이야기를 나눠볼까요?\n",
      "You : 난 누구지?\n",
      "AI : 당신은 지금 저와 대화하고 계신 사용자님이세요. 혹시 더 궁금한 점이나 이야기하고 싶은 것이 있으시면 말씀해 주세요!\n",
      "You : 내가 방금 뭐라고 했어?\n",
      "AI : 당신은 방금 \"난 누구지?\"라고 말씀하셨어요. 혹시 더 궁금한 점이 있으시면 언제든 말씀해 주세요!\n",
      "You : 그 전엔?\n",
      "AI : 그 전에 하신 말씀은 \"넌 누구야?\"였어요. 계속해서 궁금한 점이나 이야기하고 싶은 것이 있으면 말씀해 주세요!\n",
      "You : 그그 전엔?\n",
      "AI : 그 전에 하신 말씀은 \"안녕\"이었어요. 언제든지 더 이야기하고 싶으신 게 있으면 말씀해 주세요!\n",
      "You : exit\n"
     ]
    }
   ],
   "source": [
    "print(\"※ 챗봇입니다. 종료하시려면 'exit'를 입력해주세요.\")\n",
    "while True:\n",
    "    human_msg = input(\"You :\")\n",
    "    print(f\"You : {human_msg}\")\n",
    "    \n",
    "    if human_msg.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    elif human_msg == \"db\":\n",
    "        print(memory.load_memory_variables({}))\n",
    "\n",
    "    else:\n",
    "        print(\"AI : \", end=\"\")\n",
    "        ai_msg = chain.predict(question = human_msg)\n",
    "        add_message(human_msg, ai_msg)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-study (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
